{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential # To initialise the nn as a sequence of layers\n",
    "from keras.layers import Convolution2D # To make the convolution layer for 2D images\n",
    "from keras.layers import MaxPooling2D # \n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "csv=CSVLogger(\"10_encoding.log\")\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32,(2,2),input_shape = (224,224,1),strides=2,name='convo1'))\n",
    "classifier.add(Convolution2D(64,(3,3), activation = 'relu',name='convo2'))\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(64,(3,3),activation = 'relu',name='convo3'))\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classifier.add(GlobalAveragePooling2D())\n",
    "# As our model is still facing the problem so, we need to increase the regulization\n",
    "classifier.add(Dropout((0.5)))\n",
    "classifier.add(Dense(20, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2600 images belonging to 20 classes.\n",
      "Found 200 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier.compile(optimizer = 'adadelta', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "curr_path = os.getcwd()\n",
    "basefolder = os.path.dirname(curr_path)\n",
    "\n",
    "train_folder = os.path.join(basefolder, \"Dataset\\\\Train\")\n",
    "test_folder = os.path.join(basefolder, \"Dataset\\\\dev\")\n",
    "\"\"\"\n",
    "# Changes for linux\n",
    "train_folder = os.path.join(basefolder, \"Dataset/Train\")\n",
    "test_folder = os.path.join(basefolder, \"Dataset/dev\")\n",
    "\"\"\"\n",
    "train_set = train_datagen.flow_from_directory(train_folder,target_size=(224, 224),batch_size=64,class_mode='categorical',color_mode='grayscale')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_folder,target_size=(224, 224),batch_size=64,class_mode='categorical',color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "478s - loss: 2.9708 - acc: 0.0681 - val_loss: 2.9234 - val_acc: 0.1050\n",
      "Epoch 2/30\n",
      "470s - loss: 2.8475 - acc: 0.1066 - val_loss: 2.8866 - val_acc: 0.1104\n",
      "Epoch 3/30\n",
      "470s - loss: 2.7097 - acc: 0.1475 - val_loss: 2.8521 - val_acc: 0.1150\n",
      "Epoch 4/30\n",
      "470s - loss: 2.5535 - acc: 0.1926 - val_loss: 2.7670 - val_acc: 0.1552\n",
      "Epoch 5/30\n",
      "470s - loss: 2.4025 - acc: 0.2319 - val_loss: 2.7065 - val_acc: 0.1202\n",
      "Epoch 6/30\n",
      "470s - loss: 2.2642 - acc: 0.2707 - val_loss: 2.7356 - val_acc: 0.1398\n",
      "Epoch 7/30\n",
      "469s - loss: 2.1315 - acc: 0.3090 - val_loss: 2.6402 - val_acc: 0.2103\n",
      "Epoch 8/30\n",
      "469s - loss: 2.0082 - acc: 0.3465 - val_loss: 2.6213 - val_acc: 0.2098\n",
      "Epoch 9/30\n",
      "470s - loss: 1.9011 - acc: 0.3777 - val_loss: 2.6565 - val_acc: 0.2297\n",
      "Epoch 10/30\n",
      "468s - loss: 1.8046 - acc: 0.4063 - val_loss: 2.5816 - val_acc: 0.2196\n",
      "Epoch 11/30\n",
      "467s - loss: 1.7092 - acc: 0.4344 - val_loss: 2.6124 - val_acc: 0.2450\n",
      "Epoch 12/30\n",
      "467s - loss: 1.6170 - acc: 0.4645 - val_loss: 2.7752 - val_acc: 0.2403\n",
      "Epoch 13/30\n",
      "467s - loss: 1.5434 - acc: 0.4867 - val_loss: 2.8970 - val_acc: 0.2599\n",
      "Epoch 14/30\n",
      "467s - loss: 1.4724 - acc: 0.5108 - val_loss: 2.6820 - val_acc: 0.2800\n",
      "Epoch 15/30\n",
      "466s - loss: 1.4143 - acc: 0.5276 - val_loss: 2.7720 - val_acc: 0.2906\n",
      "Epoch 16/30\n",
      "467s - loss: 1.3513 - acc: 0.5471 - val_loss: 2.7425 - val_acc: 0.2754\n",
      "Epoch 17/30\n",
      "466s - loss: 1.2954 - acc: 0.5641 - val_loss: 2.9929 - val_acc: 0.2951\n",
      "Epoch 18/30\n",
      "466s - loss: 1.2527 - acc: 0.5770 - val_loss: 2.9146 - val_acc: 0.2753\n",
      "Epoch 19/30\n",
      "465s - loss: 1.2047 - acc: 0.5924 - val_loss: 3.0675 - val_acc: 0.2800\n",
      "Epoch 20/30\n",
      "466s - loss: 1.1636 - acc: 0.6054 - val_loss: 2.8755 - val_acc: 0.2799\n",
      "Epoch 21/30\n",
      "466s - loss: 1.1280 - acc: 0.6181 - val_loss: 2.7485 - val_acc: 0.3155\n",
      "Epoch 22/30\n",
      "465s - loss: 1.0908 - acc: 0.6294 - val_loss: 2.7266 - val_acc: 0.2900\n",
      "Epoch 23/30\n",
      "465s - loss: 1.0575 - acc: 0.6385 - val_loss: 2.7818 - val_acc: 0.2956\n",
      "Epoch 24/30\n",
      "465s - loss: 1.0219 - acc: 0.6520 - val_loss: 2.6101 - val_acc: 0.3299\n",
      "Epoch 25/30\n",
      "464s - loss: 0.9939 - acc: 0.6608 - val_loss: 3.0056 - val_acc: 0.2857\n",
      "Epoch 26/30\n",
      "464s - loss: 0.9666 - acc: 0.6701 - val_loss: 3.1056 - val_acc: 0.3348\n",
      "Epoch 27/30\n",
      "464s - loss: 0.9392 - acc: 0.6794 - val_loss: 3.0785 - val_acc: 0.3345\n",
      "Epoch 28/30\n",
      "464s - loss: 0.9140 - acc: 0.6867 - val_loss: 3.0962 - val_acc: 0.3301\n",
      "Epoch 29/30\n",
      "463s - loss: 0.8942 - acc: 0.6929 - val_loss: 2.9415 - val_acc: 0.3050\n",
      "Epoch 30/30\n",
      "463s - loss: 0.8744 - acc: 0.7009 - val_loss: 3.0384 - val_acc: 0.3502\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit_generator(train_set,steps_per_epoch=2600,epochs=30,validation_data=test_set,validation_steps=200,callbacks=[csv],verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.save(\"10_encoding.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = load_model(\"10_encoding.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "red_plat =  ReduceLROnPlateau(monitor='val_loss', factor=0.75,patience=4, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "467s - loss: 0.8466 - acc: 0.7085 - val_loss: 3.0272 - val_acc: 0.3350\n",
      "Epoch 2/30\n",
      "464s - loss: 0.8277 - acc: 0.7151 - val_loss: 3.6174 - val_acc: 0.3152\n",
      "Epoch 3/30\n",
      "464s - loss: 0.8101 - acc: 0.7199 - val_loss: 3.6845 - val_acc: 0.3159\n",
      "Epoch 4/30\n",
      "464s - loss: 0.7938 - acc: 0.7269 - val_loss: 3.1953 - val_acc: 0.3201\n",
      "Epoch 5/30\n",
      "464s - loss: 0.7798 - acc: 0.7320 - val_loss: 3.2238 - val_acc: 0.3555\n",
      "Epoch 6/30\n",
      "464s - loss: 0.7625 - acc: 0.7382 - val_loss: 3.0715 - val_acc: 0.3501\n",
      "Epoch 7/30\n",
      "464s - loss: 0.7320 - acc: 0.7471 - val_loss: 3.3985 - val_acc: 0.3553\n",
      "Epoch 8/30\n",
      "463s - loss: 0.7222 - acc: 0.7511 - val_loss: 3.2817 - val_acc: 0.3499\n",
      "Epoch 9/30\n",
      "464s - loss: 0.7112 - acc: 0.7543 - val_loss: 3.5124 - val_acc: 0.3200\n",
      "Epoch 10/30\n",
      "463s - loss: 0.6997 - acc: 0.7585 - val_loss: 3.3183 - val_acc: 0.3457\n",
      "Epoch 11/30\n",
      "463s - loss: 0.6849 - acc: 0.7639 - val_loss: 3.5806 - val_acc: 0.3351\n",
      "Epoch 12/30\n",
      "463s - loss: 0.6754 - acc: 0.7664 - val_loss: 3.4625 - val_acc: 0.3596\n",
      "Epoch 13/30\n",
      "464s - loss: 0.6697 - acc: 0.7687 - val_loss: 3.6427 - val_acc: 0.3597\n",
      "Epoch 14/30\n",
      "463s - loss: 0.6603 - acc: 0.7722 - val_loss: 3.7119 - val_acc: 0.3698\n",
      "Epoch 15/30\n",
      "463s - loss: 0.6455 - acc: 0.7777 - val_loss: 3.3791 - val_acc: 0.3699\n",
      "Epoch 16/30\n",
      "463s - loss: 0.6439 - acc: 0.7793 - val_loss: 3.5214 - val_acc: 0.3457\n",
      "Epoch 17/30\n",
      "464s - loss: 0.6361 - acc: 0.7807 - val_loss: 3.5973 - val_acc: 0.3600\n",
      "Epoch 18/30\n",
      "463s - loss: 0.6334 - acc: 0.7808 - val_loss: 3.8437 - val_acc: 0.3502\n",
      "Epoch 19/30\n",
      "463s - loss: 0.6231 - acc: 0.7851 - val_loss: 3.5642 - val_acc: 0.3652\n",
      "Epoch 20/30\n",
      "463s - loss: 0.6167 - acc: 0.7865 - val_loss: 3.6570 - val_acc: 0.3596\n",
      "Epoch 21/30\n",
      "463s - loss: 0.6111 - acc: 0.7884 - val_loss: 3.6389 - val_acc: 0.3501\n",
      "Epoch 22/30\n",
      "463s - loss: 0.6074 - acc: 0.7910 - val_loss: 3.7483 - val_acc: 0.3649\n",
      "Epoch 23/30\n",
      "463s - loss: 0.6024 - acc: 0.7937 - val_loss: 3.6490 - val_acc: 0.3654\n",
      "Epoch 24/30\n",
      "464s - loss: 0.5977 - acc: 0.7940 - val_loss: 3.6353 - val_acc: 0.3550\n",
      "Epoch 25/30\n",
      "463s - loss: 0.5971 - acc: 0.7934 - val_loss: 3.6578 - val_acc: 0.3599\n",
      "Epoch 26/30\n",
      "463s - loss: 0.5933 - acc: 0.7950 - val_loss: 3.7819 - val_acc: 0.3550\n",
      "Epoch 27/30\n",
      "463s - loss: 0.5884 - acc: 0.7975 - val_loss: 3.5705 - val_acc: 0.3752\n",
      "Epoch 28/30\n",
      "464s - loss: 0.5848 - acc: 0.7983 - val_loss: 3.6772 - val_acc: 0.3742\n",
      "Epoch 29/30\n",
      "463s - loss: 0.5874 - acc: 0.7972 - val_loss: 3.6821 - val_acc: 0.3757\n",
      "Epoch 30/30\n",
      "463s - loss: 0.5801 - acc: 0.8003 - val_loss: 3.7435 - val_acc: 0.3756\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit_generator(train_set,steps_per_epoch=2600,epochs=30,validation_data=test_set,validation_steps=200,callbacks=[csv,red_plat],verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.save(\"10_encoding2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
